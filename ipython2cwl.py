
from datetime import datetime, timedelta
from textwrap import dedent
from airflow.models import Param, Variable
# The DAG object; we'll need this to instantiate a DAG
from airflow import DAG, AirflowException
from airflow.operators.python_operator import PythonOperator, PythonVirtualenvOperator
# Operators; we need this to operate!


def repo2cwl_function(params):
    """Convert a repository to a CWL workflow

    Returns:
        _type_: _description_
    """
    import pendulum
    import os
    from ipython2cwl.repo2cwl import repo2cwl
    from airflow.providers.amazon.aws.hooks.s3 import S3Hook
    import yaml
    try:
        from yaml import CLoader as Loader
    except ImportError:
        from yaml import Loader
    
    now = pendulum.now()

    #s3 variables
    AWS_S3_CONN_ID = 's3_prod'
    source_s3 = S3Hook(AWS_S3_CONN_ID)
    specs_s3 = []
    bucket_name = "components"
    component_name = params["component_name"]
    git_url = params["url"]
    #store the image_name generated by repo2cwl
    image_name = ""

    #trigger repo2cwl
    directory = os.path.abspath(os.path.dirname(__file__))
    cwl_dir = os.path.join(directory, f"cwl_{now}")
    if not os.path.exists(cwl_dir):
        os.mkdir(cwl_dir)
    exit_code = repo2cwl([git_url, "-o", cwl_dir])
    

    #upload specs to s3
    specs = os.listdir(cwl_dir)
    
    
    for spec in specs:
        file_path = os.path.join(cwl_dir, spec)
        dest = f"components/{component_name}-{spec}"
        source_s3.load_file(file_path, dest, bucket_name, replace=True)
        link = f"https://s3.mint.isi.edu/{bucket_name}/{dest}"
        spec_object = {"name": spec, "localPath": spec, "remotePath": f"{git_url}/{spec}", "inferredBy": "ipython2cwl", "spec": link}
        specs_s3.append(spec_object)

    
    #extract docker image from common workflow spec
    if len(specs) > 0:
        file_path = os.path.join(cwl_dir, specs[0])
        with open(file_path, "r", encoding='utf8') as file:
            parsed = yaml.load(file, Loader=Loader)
        image_name = parsed["hints"]["DockerRequirement"]["dockerImageId"]

        

    #return the image_name and specs on s3
    response =  {"image_name": image_name, 'notebooks': specs_s3}
    return response




def login_push_function(task_instance, **kwargs):
    import json
    #obtain the response from repo2cwl task
    values_repo2cwl = task_instance.xcom_pull(task_ids="repo2cwl")
    
    #get the image generated by cwl
    image_name = values_repo2cwl['image_name']
    notebooks = values_repo2cwl['notebooks']
    
    #obtain the parameters from dag
    params = kwargs["params"]
    
    #define the constants
    DOCKER_REPO = "mintcomponents"
    component_image_name = params['component_name']
    tag =  kwargs['ds_nodash']
    
    #prepare the docker client
    import docker
    client = docker.from_env()
    USERNAME =  Variable.get("docker_username")
    PASSWORD = Variable.get("docker_password")
    client.login(USERNAME, PASSWORD)
    

    #get the image_name generated by cwl
    image = client.images.get(image_name)
    
    #tag the image with aw pretty name
    new_image_name = f"{DOCKER_REPO}/{component_image_name}"
    image.tag(new_image_name, tag=tag)
    
    #push the new image
    try:
        client.api.push(new_image_name, tag)
    except:
        raise AirflowException("unable to push")
    
    response_object = {'name': new_image_name, 'tag': tag, 'notebooks': notebooks}
    return json.dumps(response_object)
    
    
with DAG(
    'ipython2mint',
    # These args will get passed on to each operator
    # You can override them on a per-task basis during operator initialization
    default_args={
        'depends_on_past': False,
        'email': ['maxiosorio@gmail.com'],
        'email_on_failure': False,
        'email_on_retry': False,
        'retries': 0,
        'retry_delay': timedelta(minutes=5),
    },
    params={
        "url": Param(
            default="https://github.com/mosoriob/MIC_model",
            type="string"
        ),
        "component_name": Param(
            default='cwl_test',
            type="string"
        ),
    },
    description='List notebook from a git repository',
    catchup=False,
    tags=['mic', 'production'],
    start_date=datetime(2021, 1, 1),
) as dag:
    
    import os

    repo2cwl = PythonVirtualenvOperator(
        task_id='repo2cwl',
        requirements=['ipython2cwlmosorio @ git+https://github.com/mosoriob/ipython2cwl@v0.0.6', 'ipython_genutils'],
        python_callable=repo2cwl_function,
        op_kwargs={'values': '{{ params.component_name }}'},
        dag=dag)

    login_push = PythonOperator(
        task_id='login_push_dockerhub',
        python_callable=login_push_function,
        provide_context=True,
        dag=dag
    )
    
    
    repo2cwl >> login_push
